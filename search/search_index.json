{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u6df1\u5ea6\u5b66\u4e60\u4e0e\u533b\u5b66\u5f71\u50cf \u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u7684\u53d1\u5c55 \u533b\u5b66\u5f71\u50cf","title":"\u524d\u8a00"},{"location":"#_1","text":"","title":"\u6df1\u5ea6\u5b66\u4e60\u4e0e\u533b\u5b66\u5f71\u50cf"},{"location":"#_2","text":"","title":"\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u7684\u53d1\u5c55"},{"location":"#_3","text":"","title":"\u533b\u5b66\u5f71\u50cf"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/","text":"\u673a\u5668\u5b66\u4e60\u7b80\u4ecb \u4ec0\u4e48\u662f\u673a\u5668\u5b66\u4e60 \u673a\u5668\u5b66\u4e60\u7684\u5e94\u7528 \u91cd\u65b0\u8ba4\u8bc6\u5206\u7c7b \u673a\u5668\u5b66\u4e60\u7684\u5206\u7c7b \u6a21\u578b\u8bc4\u4f30\u548c\u9009\u62e9 \u611f\u77e5\u673a \u903b\u8f91\u56de\u5f52 \u6781\u5927\u4f3c\u7136 \u903b\u8f91\u56de\u5f52\u5b9e\u6218 Minist\u6570\u636e\u96c6\u5206\u7c7b https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html import time import matplotlib.pyplot as plt import numpy as np from sklearn.datasets import fetch_openml from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.utils import check_random_state # Turn down for faster convergence t0 = time . time () train_samples = 5000 # Load data from https://www.openml.org/d/554 X , y = fetch_openml ( \"mnist_784\" , version = 1 , return_X_y = True , as_frame = False ) random_state = check_random_state ( 0 ) permutation = random_state . permutation ( X . shape [ 0 ]) X = X [ permutation ] y = y [ permutation ] X = X . reshape (( X . shape [ 0 ], - 1 )) X_train , X_test , y_train , y_test = train_test_split ( X , y , train_size = train_samples , test_size = 10000 ) scaler = StandardScaler () X_train = scaler . fit_transform ( X_train ) X_test = scaler . transform ( X_test ) # Turn up tolerance for faster convergence clf = LogisticRegression ( C = 50.0 / train_samples , penalty = \"l1\" , solver = \"saga\" , tol = 0.1 ) clf . fit ( X_train , y_train ) sparsity = np . mean ( clf . coef_ == 0 ) * 100 score = clf . score ( X_test , y_test ) # print('Best C % .4f' % clf.C_) print ( \"Sparsity with L1 penalty: %.2f%% \" % sparsity ) print ( \"Test score with L1 penalty: %.4f \" % score ) coef = clf . coef_ . copy () plt . figure ( figsize = ( 10 , 5 )) scale = np . abs ( coef ) . max () for i in range ( 10 ): l1_plot = plt . subplot ( 2 , 5 , i + 1 ) l1_plot . imshow ( coef [ i ] . reshape ( 28 , 28 ), interpolation = \"nearest\" , cmap = plt . cm . RdBu , vmin =- scale , vmax = scale , ) l1_plot . set_xticks (()) l1_plot . set_yticks (()) l1_plot . set_xlabel ( \"Class %i \" % i ) plt . suptitle ( \"Classification vector for...\" ) run_time = time . time () - t0 print ( \"Example run in %.3f s\" % run_time ) plt . show ()","title":"\u673a\u5668\u5b66\u4e60\u7b80\u4ecb"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/#_1","text":"","title":"\u673a\u5668\u5b66\u4e60\u7b80\u4ecb"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/#_2","text":"","title":"\u4ec0\u4e48\u662f\u673a\u5668\u5b66\u4e60"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/#_3","text":"","title":"\u673a\u5668\u5b66\u4e60\u7684\u5e94\u7528"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/#_4","text":"","title":"\u91cd\u65b0\u8ba4\u8bc6\u5206\u7c7b"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/#_5","text":"","title":"\u673a\u5668\u5b66\u4e60\u7684\u5206\u7c7b"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/#_6","text":"","title":"\u6a21\u578b\u8bc4\u4f30\u548c\u9009\u62e9"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/#_7","text":"","title":"\u611f\u77e5\u673a"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/#_8","text":"","title":"\u903b\u8f91\u56de\u5f52"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/#_9","text":"","title":"\u6781\u5927\u4f3c\u7136"},{"location":"1-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B/#_10","text":"Minist\u6570\u636e\u96c6\u5206\u7c7b https://scikit-learn.org/stable/auto_examples/linear_model/plot_sparse_logistic_regression_mnist.html import time import matplotlib.pyplot as plt import numpy as np from sklearn.datasets import fetch_openml from sklearn.linear_model import LogisticRegression from sklearn.model_selection import train_test_split from sklearn.preprocessing import StandardScaler from sklearn.utils import check_random_state # Turn down for faster convergence t0 = time . time () train_samples = 5000 # Load data from https://www.openml.org/d/554 X , y = fetch_openml ( \"mnist_784\" , version = 1 , return_X_y = True , as_frame = False ) random_state = check_random_state ( 0 ) permutation = random_state . permutation ( X . shape [ 0 ]) X = X [ permutation ] y = y [ permutation ] X = X . reshape (( X . shape [ 0 ], - 1 )) X_train , X_test , y_train , y_test = train_test_split ( X , y , train_size = train_samples , test_size = 10000 ) scaler = StandardScaler () X_train = scaler . fit_transform ( X_train ) X_test = scaler . transform ( X_test ) # Turn up tolerance for faster convergence clf = LogisticRegression ( C = 50.0 / train_samples , penalty = \"l1\" , solver = \"saga\" , tol = 0.1 ) clf . fit ( X_train , y_train ) sparsity = np . mean ( clf . coef_ == 0 ) * 100 score = clf . score ( X_test , y_test ) # print('Best C % .4f' % clf.C_) print ( \"Sparsity with L1 penalty: %.2f%% \" % sparsity ) print ( \"Test score with L1 penalty: %.4f \" % score ) coef = clf . coef_ . copy () plt . figure ( figsize = ( 10 , 5 )) scale = np . abs ( coef ) . max () for i in range ( 10 ): l1_plot = plt . subplot ( 2 , 5 , i + 1 ) l1_plot . imshow ( coef [ i ] . reshape ( 28 , 28 ), interpolation = \"nearest\" , cmap = plt . cm . RdBu , vmin =- scale , vmax = scale , ) l1_plot . set_xticks (()) l1_plot . set_yticks (()) l1_plot . set_xlabel ( \"Class %i \" % i ) plt . suptitle ( \"Classification vector for...\" ) run_time = time . time () - t0 print ( \"Example run in %.3f s\" % run_time ) plt . show ()","title":"\u903b\u8f91\u56de\u5f52\u5b9e\u6218"},{"location":"2-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/","text":"","title":"2 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc"},{"location":"3-Tensorflow%E7%AE%80%E4%BB%8B/","text":"","title":"3 Tensorflow\u7b80\u4ecb"},{"location":"4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98/","text":"Deep Skip connection Dropout BatchNormalization","title":"4 \u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5b9e\u6218"},{"location":"4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98/#deep","text":"","title":"Deep"},{"location":"4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98/#skip-connection","text":"","title":"Skip connection"},{"location":"4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98/#dropout","text":"","title":"Dropout"},{"location":"4-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%AE%9E%E6%88%98/#batchnormalization","text":"","title":"BatchNormalization"},{"location":"5-%E5%B0%8F%E6%A0%B7%E6%9C%AC%E5%AD%A6%E4%B9%A0/","text":"","title":"5 \u5c0f\u6837\u672c\u5b66\u4e60"},{"location":"%E7%94%9F%E6%88%90%E5%AF%B9%E6%8A%97%E7%BD%91%E7%BB%9C/","text":"","title":"\u751f\u6210\u5bf9\u6297\u7f51\u7edc"}]}